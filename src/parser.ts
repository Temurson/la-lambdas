import { Token } from 'tokenizr'

/*
x                               # => (Var "x")
位x->x                           # => (Abs "x" (Var "x"))
位x->位y->x                       # => (Abs "x" (Abs "y" (Var "x")))
位x->(\y->x) a                   # =>
\x->\y->\z->x y \y->(y y)       # => \y->\z->(y y)
*/

// need to count number of open parens in the process
const parse = (tokens: Token[]): [Expr, Token[]] => {
    switch (tokens[0].type) {
    case 'lparen':
        parse()
        break;
    case 'lambda':
        // parse variable, then parse body, then construct Abs
    }

    return [null, []]
}
